set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_col <- grep("^[Ii][Ll].*", names(training))
IL_columns <- training[,IL_col]
new_training <- cbind(IL_columns, diagnosis)
new_testing <- testing[, c(names(testing)[IL_col], "diagnosis")]
non_pca <- train(diagnosis ~., data = new_testing, method = "glm")
non_pca <- train(diagnosis ~., data = new_testing, method = "glm")
library(e1071)
install.packages('e1071', dependencies=TRUE)
non_pca <- train(diagnosis ~., data = new_testing, method = "glm")
new_training <- training[, c(names(training)[IL_col], "diagnosis")]
non_pca <- train(diagnosis ~., data = new_training, method = "glm")
non_pca_result <- confusionMatrix(new_testing[, 13], predict(non_pca_model, new_testing[, -13]))
non_pca_result <- confusionMatrix(new_testing[, 13], predict(non_pca, new_testing[, -13]))
non_pca_result
pc_training_obj <- preProcess(new_training[, -13], method=c('pca'), thresh=0.8)
pc_training_preds <- predict(pc_training_obj, new_training[, -13])
pc_testing_preds <- predict(pc_training_obj, new_testing[, -13])
pca_model <- train(new_training$diagnosis ~ ., data=pc_training_preds, method="glm")
pca_model <- train(diagnosis ~ ., data=pc_training_preds, method="glm")
library(caret)
library(ElemStatLearn)
library(pgmm)
library(rpart)
install.packages("pgmm")
library(pgmm)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(ElemStatLearn)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.7, list = FALSE)
training <- segmentationOriginal[inTrain,]
test <- segmentationOriginal[-inTrain,]
dim(training)
dim(testing)
test <- segmentationOriginal[-inTrain,]
dim(training)
dim(test)
model1 <- train(Case ~ ., data = training, method = rpart)
model1 <- train(Case ~ ., data = training, method = "rpart")
library(rattle)
install.packages("rattle")
library(rattle)
fancyRpartPlot(model1$finalModel)
library(rattle)
fancyRpartPlot(model1$finalModel)
plot(model1$finalModel)
text(model1$finalModel, use.n = TRUE, all = TRUE, cex = .8)
plot(model1$finalModel)
text(model1$finalModel, use.n = TRUE, all = TRUE, cex = .8)
plot(model1$finalModel)
text(model1$finalModel, use.n = TRUE, all = TRUE)
model1$finalModel
head(segmentationOriginal)
model1 <- train(Class ~ ., data = training, method = "rpart")
model1$finalModel
install.packages("rattle")
library(rattle)
install.packages("rattle")
library(rattle)
seed(125)
model1 <- train(Class ~ ., data = training, method = "rpart")
library(caret)
library(ElemStatLearn)
install.packages("pgmm")
library(pgmm)
library(rpart)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.7, list = FALSE)
training <- segmentationOriginal[inTrain,]
test <- segmentationOriginal[-inTrain,]
dim(training)
dim(test)
seed(125)
model1 <- train(Class ~ ., data = training, method = "rpart")
set.seed(125)
model1 <- train(Class ~ ., data = training, method = "rpart")
model1$finalModel
library(caret)
fancyRpartPlot(model1$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(model1$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
model2 <- train(Area ~., data = olive, method = "rpart")
newdata = as.data.frame(t(colMeans(olive)))
predict(model2, newdata = newdata)
head(olive)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
head(trainSA)
model4 <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm", family = "binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA, model4)
missClass(model4, trainSA)
missClass(testSA$chd, predict(model4, newdata = trainSA))
missClass(trainSA$chd, predict(model4, newdata = trainSA))
missClass(testSA$chd, predict(model4, newdata = testSA))
missClass(trainSA$chd, predict(model4, newdata = trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
randomForest(y ~ ., data = vowel.train)
install.packages("randomForest")
library(randomForest)
randomForest(y ~ ., data = vowel.train)
model5 <- randomForest(y ~ ., data = vowel.train)
varImp(model5)
order(varImp(model5), decreasing = TRUE)
set.seed(33833)
model5 <- randomForest(y ~ ., data = vowel.train)
order(varImp(model5), decreasing = TRUE)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
head(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(caret)
model_rf <- train(y ~ ., data = vowel.train, method = "rf")
model_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
model_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
model_rf$confusion
predict_rf <- predict(model_rf, data = vowel.test)
predict_gbm <- predict(model_gbm, data = vowel.test)
confusionMatrix(data = predict_rf, reference = vowel.test$y)
confusionMatrix(vowel.test$y, predict_rf)
confusionMatrix(vowel.test$y, predict_rf$y)
predict_rf
confusionMatrix(vowel.test$y, predict_rf)
set.seed(33833)
model_rf <- train(y ~ ., data = vowel.train, method = "rf")
model_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
predict_rf <- predict(model_rf, data = vowel.test)
predict_gbm <- predict(model_gbm, data = vowel.test)
confusionMatrix(vowel.test$y, predict_rf)
confusionMatrix(vowel.test$y, predict_gbm)
confusionMatrix(vowel.test$y, predict_rf)$overall
dim(vowel.test$y)
vowel.test$y
dim(predict_rf)
predict_rf
data(vowel.train)
data(vowel.test)
library(caret)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
model_rf <- train(y ~ ., data = vowel.train, method = "rf")
model_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
predict_rf <- predict(model_rf, data = vowel.test)
predict_gbm <- predict(model_gbm, data = vowel.test)
confusionMatrix(vowel.test$y, predict_rf)$overall
confusionMatrix(vowel.test$y, predict_gbm)
dim(predict_rf)
predict_rf <- predict(model_rf, newdata = vowel.test)
predict_gbm <- predict(model_gbm, newdata = vowel.test)
confusionMatrix(vowel.test$y, predict_rf)$overall
confusionMatrix(vowel.test$y, predict_gbm)
confusionMatrix(vowel.test$y, predict_rf)
confusionMatrix(vowel.test$y, predict_gbm)
the_same_index <- (predict_rf == predict_gbm)
predict_both <- predict_rf[the_same_index,]
confusionMatrix(vowel.test$y[the_same_index], predict_rf[the_same_index])
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62443)
model_rf <- train(diagnosis ~., data = training, method = "rf")
model_gbm <- train(diagnosis ~., data = training, method = "gbm")
model_lda <- train(diagnosis ~., data = training, method = "lda")
pred_rf <- predict(model_rf, newdata = test)
pred_gbm <- predict(model_gbm, newdata = test)
pred_lda <-  predict(model_lda, newdata = test)
pred_rf <- predict(model_rf, newdata = testing)
pred_gbm <- predict(model_gbm, newdata = testing)
pred_lda <-  predict(model_lda, newdata = testing)
stacked <- data.frame(pred_rf, pred_gbm, pred_lda, testing$diagnosis)
model_stacked <- train(diagnosis~., data = stacked, method = "rf")
dim(stacked)
stacked <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
model_stacked <- train(diagnosis~., data = stacked, method = "rf")
pred_stacked <- predict(model_stacked, newdata = testing)
confusionMatrix(pred_rf, testing$diagnosis)
confusionMatrix(pred_gbm, testing$diagnosis)
confusionMatrix(pred_lda, testing$diagnosis)
confusionMatrix(pred_stacked, testing$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
pred_stacked <- predict(model_stacked, newdata = testing)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
model_lasso <- train(CompressiveStrength, data = concrete, method = "lasso")
model_lasso <- train(CompressiveStrength, data = training, method = "lasso")
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
model_lasso <- train(CompressiveStrength, data = training, method = "lasso")
model_lasso <- train(CompressiveStrength~., data = training, method = "lasso")
model_lasso <- train(CompressiveStrength~., data = training, method = "lasso")
plot.enet(model_lasso)
plot.enet(model_lasso, xvar = "penalty")
plot.enet(model_lasso$finalModel, xvar = "penalty")
plot.enet(model_lasso$finalModel, xvar = "penalty",color = TRUE)
plot.enet(model_lasso$finalModel, xvar = "penalty", use.color = TRUE)
library(lubridate)
dat = read.csv("~/Downloads/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
install.packages("forecast")
library(forecast)
model_ts <- bats(tstrain, data = training)
head(dat)
model_ts <- bats(visitsTumblr, data = training)
model_ts <- bats(visitsTumblr~., data = training)
model_ts <- bats(tstrain)
forecast_ts <- forecast.bats(model_ts, level=95, h=nrow(testing))
acc <- accuracy(fcast, testing$visitsTumblr)
acc <- accuracy(forecast_ts, testing$visitsTumblr)
acc
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
library(e1071)
model_svm <- svm(CompressiveStrength~., data = training)
predict_svm <- predict(model_svm, newdata = testing)
confusionMatrix(predict_svm, testing$CompressiveStrength)
url_training <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
url_testing <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(url_training, "~/Dropbox/Data_Science/pml-training.csv", method = "curl")
download.file(url_testing, "~/Dropbox/Data_Science/pml-training.csv", method = "curl")
url_training <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
url_testing <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(url_training, "~/Dropbox/Data_Science/pml-training.csv", method = "curl")
download.file(url_testing, "~/Dropbox/Data_Science/pml-testing.csv", method = "curl")
url_training <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
url_testing <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
dest_training <- "~/Dropbox/Data_Science/pml-training.csv"
dest_testing <- "~/Dropbox/Data_Science/pml-testing.csv"
download.file(url_training, dest_training, method = "curl")
download.file(url_testing, dest_testing, method = "curl")
read.csv(dest_training)
read.csv(dest_testing)
head(url_training)
head(training)
training <- read.csv(dest_training)
testing <- read.csv(dest_testing)
head(training)
library(caret)
nzv_training <- nearZeroVar(training, saveMetrics = TRUE)
nzv_training
inTrain <- createDataPartition(y=training$classe, p = 0.75, list = FALSE)
train1 <- training[inTrain, ]
test1 <- training[-inTrain, ]
dim(train1)
dim(test1)
nzv_training <- nearZeroVar(train1, saveMetrics = TRUE)
nzv_training
nzv <- nearZeroVar(train1, saveMetrics = TRUE)
train1 <- train1[, -nzv]
test1 <- test1[, -nzv]
nzv <- nearZeroVar(train1)
train1 <- train1[, -nzv]
test1 <- test1[, -nzv]
dim(train1)
dim(test2)
dim(test)
dim(test1\)
dim(test1)
head(train1)
class(train1$classe)
train1 <- train1[, 6:ncol(train1)]
dim(train1)
test1 <- test1[, 6:ncol(test1)]
head(train1, 50)
mostlyNA <- sapply(ptrain1, function(x) mean(is.na(x))) > 0.95
mostlyNA <- sapply(train1, function(x) mean(is.na(x))) > 0.95
mostlyNA
NAs <- sapply(train1, function(x) mean(is.na(x))) > 0.75
train1 <- train1[, -NAs]
test1 <- test1[, -NAs]
head(train1)
NAs
training <- read.csv(dest_training)
testing <- read.csv(dest_testing)
set.seed(123)
inTrain <- createDataPartition(y=training$classe, p = 0.75, list = FALSE)
train1 <- training[inTrain, ]
test1 <- training[-inTrain, ]
nzv <- nearZeroVar(train1)
train1 <- train1[, -nzv]
test1 <- test1[, -nzv]
train1 <- train1[, 6:ncol(train1)]
test1 <- test1[, 6:ncol(test1)]
head(train1, 50)
NAs <- sapply(train1, function(x) mean(is.na(x))) > 0.75
train1 <- train1[, NAs == FALSE]
test1 <- test1[, NAs == FALSE]
```
head(train1)
dim(train1)
test1 <- test1[, -54]
dim(test1)
library(rattle)
install.packages("rattle")
install.packages("rattle")
library(rattle)
install.packages("RGtk2")
install.packages("RGtk2")
library(rattle)
q()
rpart_model <- train(classe~., data = train1, method = "rpart")
library(caret)
rpart_model <- train(classe~., data = train1, method = "rpart")
library(rpart.plot)
rpart_model$finalModel
rpart_model
pred_rpart <- predict(rpart_model, newdata = test1)
confusionMatrix(pred_rpart, test1$classe)
pred_rpart
test1$classe
library(caret)
library(rattle)
library(rpart)
library(rpart.plot)
url_training <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
url_testing <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
dest_training <- "~/Dropbox/Data_Science/pml-training.csv"
dest_testing <- "~/Dropbox/Data_Science/pml-testing.csv"
download.file(url_training, dest_training, method = "curl")
download.file(url_testing, dest_testing, method = "curl")
training <- read.csv(dest_training)
testing <- read.csv(dest_testing)
set.seed(123)
inTrain <- createDataPartition(y=training$classe, p = 0.75, list = FALSE)
train1 <- training[inTrain, ]
test1 <- training[-inTrain, ]
The next step is to analyze the raw data and tidying the covariates on the training set. We exclude variables with very little variability, as they are not going to be useful predictors. We also remove variables that for qualitative reasons are not useful for prediction (observation identifier, username and timestamp variables). An inspection of the head of the dataset also suggests that some variables are mostly NAs, so we remove those variables for which more than 75% of observations are missing. 53 predictors, plus the variable classe, which is to be predicted, remain.
nzv <- nearZeroVar(train1)
train1 <- train1[, -nzv]
test1 <- test1[, -nzv]
train1 <- train1[, 6:ncol(train1)]
test1 <- test1[, 6:ncol(test1)]
head(train1, 50)
NAs <- sapply(train1, function(x) mean(is.na(x))) > 0.75
train1 <- train1[, NAs == FALSE]
test1 <- test1[, NAs == FALSE]
rpart_model <- train(classe~., data = train1, method = "rpart")
rpart_model
rpart_model$finalModel
pred_rpart <- predict(rpart_model, newdata = test1)
confusionMatrix(pred_rpart, test1$classe)
rpart_model2 <- train(classe~., data = train1, preProcess("pca"), method = "rpart")
train1
rpart_model2 <- train(classe~., data = train1, preProcess("pca"), method = "rpart")
rpart_model2 <- train(classe~., data = train1, preProcess = "pca", method = "rpart")
rpart_model2
pred_rpart2 <- predict(rpart_model2, newdata = test1)
confusionMatrix(pred_rpart2, test1$classe)
rpart_model3 <- train(classe~., data = train1, trainControl = "cv", method = "rpart")
rpart_model3
rf_model <- train(classe~., data = train1, method = "rf")
rf_model <- train(classe~., data = train1, method = "rf", trControl = trainControl(method = "cv", number = 3))
rf_model$finalModel
pred_rf <- predict(rf_model, newdata = test1)
confusionMatrix(pred_rf, test1$classe)
testing <- testing[, -nzv]
testing <- testing[, 6:ncol(testing)]
testing <- testing[, NAs == FALSE]
pred_final <- predict(rf_model, newdata = testing)
pred_final
install.packages("fivethirtyeight")
library("fivethirtyeight")
library(fivethirtyeight)
college <- data("college_all_ages")
head(college)
college
head("college_all_ages")
college_all_ages
head(college_all_ages)
unique(college_all_ages$major)
unique(college_all_ages$major_category)
data <- college_all_ages
head(data)
data("college_majors")
names <- unique(data$major_category)
names
?as.vector
names <- as.vector(unique(data$major_category))
names
shiny::runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
pch
pch()
pch = 0:18
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
data_subset <- data[data$major_category == input]
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
head(college_all_ages)
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
runApp('Dropbox/Data_Science/Data_Products/Shiny_App/Data_App')
install.packages("RWeka")
install.packages(
"RWekajars"
)
install.packages("RWeka")
install.packages("RJava")
install.packages("rJava")
install.packages("RWeka")
library("rJava")
library("RWekajars")
install.packages("RWeka")
install.packages("RWeka")
install.packages("RWeka")
library(rJava)
install.packages("RWeka")
install.packages("rJava",type='source')
install.packages("rJava", type = "source")
install.packages("RWeka")
setwd("~/Dropbox/Data_Science/Swiftkey_Project/Shiny_App/Next_Word_Predictor/data")
fivegram_table <- data.table(read.csv("5gram_table.csv"))
setkey(fivegram_table, "Word1", "Word2", "Word3", "Word4", "LastWord")
fourgram_table <- data.table(read.csv("4gram_table.csv"))
setkey(fourgram_table, "Word1", "Word2", "Word3", "LastWord")
trigram_table <- data.table(read.csv("3gram_table.csv"))
setkey(trigram_table, "Word1", "Word2", "LastWord")
bigram_table <- data.table(read.csv("2gram_table.csv"))
setkey(bigram_table, "Word1", "LastWord")
library(tm)
library(ngram)
library(readr)
library(RWeka)
library(dtplyr)
library(caret)
library(qdap)
library(tm)
library(ngram)
library(readr)
library(RWeka)
library(data.table)
library(stringr)
setwd("~/Dropbox/Data_Science/Swiftkey_Project/Shiny_App/Next_Word_Predictor/data")
fivegram_table <- data.table(read.csv("5gram_table.csv"))
setkey(fivegram_table, "Word1", "Word2", "Word3", "Word4", "LastWord")
fourgram_table <- data.table(read.csv("4gram_table.csv"))
setkey(fourgram_table, "Word1", "Word2", "Word3", "LastWord")
trigram_table <- data.table(read.csv("3gram_table.csv"))
setkey(trigram_table, "Word1", "Word2", "LastWord")
bigram_table <- data.table(read.csv("2gram_table.csv"))
setkey(bigram_table, "Word1", "LastWord")
